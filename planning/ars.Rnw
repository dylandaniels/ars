\documentclass{article}
\usepackage{titling}
\usepackage[margin=1.25in]{geometry}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}

\setlength{\droptitle}{-10em}
\author{Dylan Daniels, Jiang Zhu, Tian Xia, Birce Tezel}
\title{ARS Final Project \\ \url{github.com/dylandaniels/ars}}

\begin{document}

\maketitle

\subsection*{Implementation}
The core part of the algorithm is implemented in the \texttt{ars()} function; helper functions are implemented in small, modular components. The more complicated part of the algorithm involves sampling from the distribution $s_k(x) = u_k(x) / \int_D u_k(x') dx' = c \ u_k(x)$. The basic strategy was to use inverse transform sampling. To do this, we first need to find the normalizing constant $c := 1 / \int_D u_k(x') dx':$


$$
\int_D u_k(x') dx' = \sum_{j = 0}^{k+1} I_j,
$$

where $$I_j := \int_{z_{j-1}}^{z_j} \exp(h(x_j) + (x' - x_j) h'(x_j)) dx'.$$ Notice that the explicit form of $I_j$ depends on whether $h'(x_j)=0$ or not. Therefore we have,
$$ I_j = \begin{cases}
	(z_j-z_{j-1}) \exp (h(x_j)) \quad \text{if} \quad h'(x_j) = 0, \vspace{2mm} \\
	\frac{\exp u_k(z_j)  - \exp u_k(z_{j-1}) }{h'(x_j)} \quad \text{otherwise}.
	\end{cases} $$

Next, in order to use the inverse CDF method for sampling, we must find the CDF for $s_k(x)$, $S_k(x) = c \int_{z_0}^x u_k(x') dx'$:

$$
S_k(x) = c \left(\sum_{j = 0}^{t - 1} I_j + \int_{z_{t-1}}^x \exp(h(x_t) + (x' - x_t) h'(x_t)) dx') \right),
$$

\noindent where $t$ is the index of which interval of $z$'s that $x$ lies in. Formally, it is $t(x) = \{1\leq i \leq k+1 : x \in (z_{i-1}, z_i)\}$. For convenience, let $$\texttt{partialSums[t-1]} := \sum_{j = 1}^{t - 1} I_j$$ and notice that our normalizing constant can be expressed as $c = \texttt{1/partialSums[k]}$. Moreover, let us define $$J_{t-1}(x) := \int_{z_{t-1}}^x \exp(h(x_t) + (x' - x_t) h'(x_t)) dx').$$ Then we have,
$$
S_k(x) = c \left(\text{\texttt{partialSums[t-1]}} + J_{t-1}(x) \right),
$$
where
$$
J_{t-1}(x) = \begin{cases}
	\exp\big(h(x_t)\big)(x-z_{t-1}) \quad \text{if} \quad h'(x_t) = 0, \vspace{2mm}\\
 	\frac{\exp u_k(x) - \exp u_k(z_{t-1})}{h'(x_t)} \quad \text{otherwise}.
 \end{cases}
$$


Now, we can determine the inverse transform $S_k^{-1}(U)$, where $U \sim$ Uniform[0,1]. Because $t$ is actually a function of $x$, it too must be inverted. Intuitively, we want to pick the biggest $t$ such that $S_k(z_{t-1}) < U$. Formally, $t(U) = \{ 1\leq i \leq k+1 : U \in (c \times \text{\texttt{partialSums[i - 1]}}, c\times \text{\texttt{partialSums[i]}})\}$. Solving for the inverse, we have:

$$
S_k^{-1}(U) = \begin{cases}
	\frac{\frac{U}{c} - \texttt{partialSums[t-1]}}{\exp \big(h(x_t) \big)} + z_{t-1} \quad \text{if} \quad h'(x_t) = 0, \vspace{2mm} \\
 	\frac{\log\left(h'(x_t) (\frac{U}{c} - \text{\texttt{partialSums[t-1]}}) + \exp u_k(z_{t-1})\right) - h(x_t)}{h'(x_t)} + x_t \quad \text{otherwise}.
 \end{cases}
$$


\subsection*{Testing}
We have written unit tests for each individual helper function, as well as tests for our main \texttt{ars()} function. Due to the stochastic nature of some of our functions, many tests are explicitly set with a seed
for the pseduo-random number generator so that their output becomes deterministic, and thus, verifiable by
an \texttt{expect\_equal()} assertion.

In addition to automated testing, we checked if the samples we created are statistically correct. We first compared the histograms of our samples to the corresponding density function and visually checked if there were any unexpected behavior. These histograms along with the density function curves are presented in Figure \ref{fig:histograms}. Second, we ran a series of Kolmogorov-Smirnov (KS) tests to verify that the empirical CDF of our generated samples matched the CDF of the true distribution. The KS test tests the null the hypothesis that the samples drawn from our algorithm match the target distribution. Thus, for the following tests, if our algorithm is working correclty, we expect high $p$-values. We ran the following KS tests:

<<echo=FALSE>>=
ddgamma=Vectorize(function(x,alpha=4,beta=5)
{
  return(dgamma(x,shape=alpha,rate=beta))
})

ddbeta=Vectorize(function(x,alpha=2,beta=2)
{
  return(dbeta(x,shape1=alpha,shape2=beta))
})

ddchisqu=Vectorize(function(x,k=6)
{
  return(1/(2^(k/2)*gamma(k/2))*x^(k/2-1)*exp(-x/2))
})

ppgamma=Vectorize(function(x,alpha=4,beta=5)
{
  return(pgamma(x,shape=alpha,rate=beta))
})

ppbeta=Vectorize(function(x,alpha=2,beta=2)
{
  return(pbeta(x,shape1=alpha,shape2=beta))
})

ddchisq=Vectorize(function(x,df=6)
{
  return(dchisq(x,df))
})

ppchisq=Vectorize(function(x,df=6)
{
  return(pchisq(x,df))
})
@


<<>>=
#Load the package ars
devtools::install()
library(ars)

#Normal distribution with mean 0 and standard deviation 1
set.seed(0)
samples=ars(n=1000, g=dnorm, dg=NULL, initialPoints=NULL, leftbound=-Inf, rightbound=Inf)
print(ks.test(samples,pnorm)$p.value)

#Uniform disribution between 0 an 1
set.seed(0)
samples=ars(1000, g=dunif,leftbound=0, rightbound=1)
print(ks.test(samples,punif)$p.value)

#Gamma distribution with shape parameters alpha = 4, beta = 5
set.seed(0)
samples=ars(1000, g=ddgamma,leftbound=0, rightbound=Inf)
print(ks.test(samples,ppgamma)$p.value)

#Beta distribution with shape parameters alpha = 2, beta = 2
set.seed(0)
samples=ars(1000, g=ddbeta,leftbound=0, rightbound=1)
print(ks.test(samples,ppbeta)$p.value)

#Chi-squared distribution with d.f. = 4
set.seed(0)
samples=ars(1000, g=ddchisq,leftbound=0, rightbound=Inf)
print(ks.test(samples,ppchisq)$p.value)
@

\begin{figure}
\centering
  \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[scale = 0.4]{standard_normal.png}
  \end{subfigure}
  \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[scale = 0.4]{uniform.png}
  \end{subfigure} \\
    \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[scale = 0.4]{gamma.png}
  \end{subfigure}
  \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[scale = 0.4]{beta.png}
  \end{subfigure} \\
  \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[scale = 0.4]{chisq.png}
  \end{subfigure}
  \caption{Histograms of the samples generated by \texttt{ars} compared to the true density functions.} \label{fig:histograms}
\end{figure}


\subsection*{Contributions}
Jiang Zhu wrote the squeezing function, the precheck function and some part of the ars function. Jiang Zhu also wrote tests for squeezing function, precheck function and for common cases of the ars function.

Tian Xia wrote the envelope funciton, returning the value evaluated by the $u_k(x)$, test code for testing envelope function, intersects function, update function and part of the test code of the main function under some abnormal input functions.

Birce wrote the code for finding initial set of abscissae points if not provided by the user, finding and updating the intersection points of the envelope function, updating abscissae and vectors \texttt{hx} and \texttt{dhx} and finally the accept/reject function that takes returns the decision regarding a new sampled point.

Dylan Daniels wrote the code for sampling from the envelope function, including its tests. In addition, he spearheaded the auxiliary tasks, such as setting up the git repo and creating the package.

\end{document}
